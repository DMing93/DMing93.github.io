# Linux内存管理原理

## 虚拟地址、物理地址、逻辑地址、线性地址

1. 虚拟地址又叫线性地址。Linux**没有采用分段地址**，所以逻辑地址和虚拟地址（线性地址）是一个概念。
2. 物理地址对应存储器，存储器以字节为单位，每一个字节单元给以唯一的存储器地址。
3. **内核**的虚拟地址和物理地址，**大部分只差一个线性偏移量**。
4. **用户空间**的虚拟地址和线性地址则采用**多级页表**进行映射，但仍称之为线性地址。

## DMA/HIGH_MEM/NORMAL分区

在x86架构中，**Linux内核虚拟地址空间**的划分：

- 0~3G为用户空间
- 3~4G为内核空间（注意,内核可以使用的线性地址只有1G）

内核虚拟地址空间（3~4G）又划分为三种类型的区：

- 3G之后起始的16MB **ZONE_DMA**
- 16MB~896MB      **ZONE_MORMAL**
- 896MB~1G        **ZONE_HIGHMEM**

由于内核的虚拟和物理地址只差一个偏移量：**物理地址 = 逻辑地址 - 0xC0000000**。
所以如果1G内核空间完全用来线性映射，显然物理内存也只能访问到1G区间，这明显是不合理的。

HIGHMEM就是为了解决这个问题，专门开辟的一块**不必线性映射**，可以**灵活定制映射**，以便访问1G以上物理内存的区域。

![](https://i.imgur.com/mUgg3Kf.png)

对于高端内存，它的划分如下图：

![](https://i.imgur.com/pAT2shE.jpg)

- 内核直接映射空间：**PAGE\_OFFSET~VMALLOC\_START**，**kmalloc** 和**__get\_free\_page()**分配的是这里的页面。二者是借助slab分配器，直接分配物理页在转换为逻辑地址（物理地址连续）。**适合分配小段内存**。此区域包含了内核镜像、物理页框表mem\_map等资源。
- 内核动态映射空间：**VMALLOC\_START~VMALLOC_END**,被vmalloc用到，可表示的空间较大。
- 内核永久映射空间：**PKMAP\_BASE~FIXADDR\_START**,kmap
- 内核临时映射空间：**FIXADDR\_START~FIXADDR\_TOP**,kmap_atomic

## 伙伴算法和slab分配器

**伙伴系统buddy算法解决了外部碎片的问题**。

内核在每个zone区管理着**可用的页面**，按2的幂级（order）大小排成链表队列，**存放在free\_area数组**。
![](https://i.imgur.com/rdwPvSd.gif)

### buddy避免内部碎片的努力

**物理内存的碎片化**一直是Linux操作系统的弱点之一，尽管已经有人提出了很多解决方法，但是没有哪个可以彻底解决这个问题，memory buddy分配就是解决方法之一。

我们知道**磁盘文件**也有碎片化的问题，但是磁盘文件的碎片化只会减慢系统的读写速度，并不会导致功能性错误。而且我们还可以在不影响磁盘功能的情况下进行碎片整理。而物理内存碎片则截然不同，**物理内存和操作系统给的结合太过于紧密**，以至于我们很难在运行时，进行物理内存的搬移。

在了解反碎片的原理之前，先对内存页面进行归类：

- **不可移动页面unmoveable**:在内存中位置必须固定，无法移动到其他地方，核心内核分配的大部分页面属于这一类。
- **可回收页面reclaimable**:不能直接移动，但是可以回收。此外还可以从某些源重建页面，比如映射文件中的数据属于此类别。**ksawpd**会按照一定的规则周期性回收这类页面。
- **可移动页面moveable**:可以随意的移动。属于用户空间应用程序的页属于此类页面，**它们是通过页表映射的**。因此我们只需要更新页表项，并把数据复制到新位置就可以了， **要注意，一个页面可能被多个进程共享，对应着多个页表项。

**防止碎片的方法就是把这三类page放在不同的链表上，避免不同类型页面相互干扰**。

考虑一下这种情况：一个不可移动页面位于可移动页面中间，那么我们移动或者或者回收这些页面后，这个不可移动页面阻碍着我们获得更大的连续物理空闲空间。

**此外**，每个zone区都有一个自己的**失活净页面队列**，与此对应的是两个跨zone的全局队列————**失活脏页队列**和**活跃队列**。这些队列都是通过page结构的lru指针链入的。

### slab分配器：解决内部碎片问题

**内核通常依赖于对小对象的分配**，它们会在系统生命周期内进行无数次的分配。slab缓存分配器通过对类似大小（远小于1page）的对象进行缓存而提供这种功能，从而避免了常见的内部碎片问题。

![](https://i.imgur.com/tJPDc19.gif)

很显然，slab机制是基于buddy算法的，前者是对后者的细化。

## 页面回收、侧重机制
### 关于页面的使用

在之前的一些文章中，我们了解到Linux内核会在很多情况下分配页面。

1. **内核代码可能会调用alloc\_page之类的函数，从管理物理页面的伙伴系统（管理区zone上的free_area空闲链表）上直接分配页面**。

	比如：驱动程序可能用这种方式来分配缓存；创建进程时，内核也是通过这种方式分配连续的两个页面，作为进程的thread_info结构和内核栈；**从伙伴系统分配页面是最基本的页面分配方式，其他内存分配都是基于这种方式的**。

2. **内核的许多对象都是用slab机制管理起来的**。slab就相当于对象池，它将页面“格式化”成“对象”，存放在池中供人使用。当slab中的对象不足时，slab机制会自动从伙伴系统中分配页面，并“格式化”成新的对象；

3. **磁盘高速缓存**。读写文件时，页面被从伙伴系统分配并用于磁盘高速缓存，然后磁盘上的文件数据被载入到相应的磁盘高速缓存页面中；

4. **内存映射**。这里所谓的内存映射实际上是指将内存页面映射到用户空间，供用户进程使用。进程的task\_struct->mm结构中的每一个vma就代表一个映射，而映射的真实实现则是在用户程序访问到对应的内存地址后，由缺页异常引起的页面被分配和页表被更新。

### 页面回收简述

有页面分配就有页面回收。页面回收大体分为两种：

**一、主动释放**。就像用户程序通过free函数释放曾经通过malloc函数分配的内存一样，页面的使用者明确知道页面什么时候要被使用，什么时候又不再需要了。上面提到的前两种分配方式，一般都是由内核程序主动释放的。对于直接从伙伴系统分配的页面，这是由使用者使用free\_pages之类的函数主动释放的，页面释放后被直接放归伙伴系统；从slab中分配的对象（使用kmem\_cache\_alloc函数），也是由使用者主动释放的（使用kmem\_cache\_free函数）。

**另一种页面回收方式是通过Linux内核提供的页框回收算法（PFRA）进行回收。**页面的使用者一般将页面当作某种缓存，以提高系统的运行效率。缓存一直存在固然好，但是如果缓存没有了也不会造成什么错误，仅仅是效率受到影响而已。页面的使用者不明确知道这些缓存页面什么时候最好被保留，什么时候最好被回收，这些都交给PFRA来关心。

简单的来说，PFRA要做的事就是回收这些可以被回收的页面。为了避免系统陷入页面紧缺的困境，**PFRA会在内核线程中周期性地被调用运行**。或者由于系统已经页面紧缺，试图分配页面的内核执行流程因为得不到需要的页面，而同步地调用PFRA。

上面提到的后两种分配方式，一般是由PFRA来进行回收的（或者由类似删除文件、进程退出这样的过程来同步回收）。

### PFRA回收一般页面

对于上面提到的前两种页面分配方式（直接分配页面和通过slab分配对象），也有可能需要通过PFRA来回收。

页面的使用者可以向PFRA注册回调函数（使用register_shrink函数）。然后由PFRA在适当的时机来调用这些回调函数，以触发对应页面或对象的回收。

其中比较典型的是对dentry的回收。dentry是由slab分配的，用于表示虚拟文件系统目录结构的对象。在dentry引用计数减为0的时候，dentry并不是直接被释放，而是被放到一个LRU链表中缓存起来，便于后续的使用。

而这个LRU链表中的dentry最终是要被回收的，于是虚拟文件系统在初始化时，调用了register\_shrinker注册了回收函数shrinker\_dcache\_memory。系统中所有文件系统的超级块对象被存放在一个链表中，shrinker\_dcache_memory函数扫描这个链表获取每个超级块的未被使用dentry的LRU，然后从中回收一些最老的dentry。随着dentry的释放，对应的inode将被减引用，也可能引起inode被释放。

inode被释放后也是放在一个未使用链表中，虚拟文件系统在初始化时还调用register\_shrinker注册了回调函数shrink\_icache\_memory，用来回收这些未使用的inode，从而inode中关联的磁盘高速缓存也将被释放。

另外，随着系统的运行，slab中可能会存在很多空闲对象（比如在某一对象使用的高峰过后）。PFRA中的cache_reap函数就用于回收这些多余的空闲对象，如果某些空闲对象正好能还原成一个页面，则这个页面可以被释放回伙伴系统。

cache\_reap函数要做的事情说起来很简单。系统中所有存放对象池的kmem_cache结构连成一个链表，cache_reap函数扫描其中的每一个对象池，然后寻找可以回收的页面，并将其回收。（当然，实际过程要更为复杂一些）。

### 哪些页面应该回收

至于回收，磁盘高速缓存的页面（包括文件映射的页面）都是可以被丢弃并回收的。但页面如果是脏页面，则丢弃之前必须将其写回磁盘。

而匿名映射的页面则都是不可以丢弃的，因为里面有用户程序就正在使用的数据，丢弃之后没法还原。想要回收匿名映射的页面，只好先把页面上的数据转储到磁盘，即**页面交换**。显然，页面交换的代价相对更高。

于是，除非页面被保留或被上锁（页面标记PG\_reserved/PG\_locked被置位。某些情况下，内核需要暂时性的将页面保留，避免被回收），所有的磁盘高速缓存页面都可回收，所有的匿名映射页面都可交换。

尽管可以回收的页面很多，但是显然PFRA应当尽可能少地去回收/交换页面（因为这些页面要从磁盘恢复，需要很大代价）。所以，PFRA仅当必要时才回收/交换一部分很少被使用的页面。每次回收的页面数是一个经验值：32。

于是，所有这些磁盘高速缓存页面和匿名映射页面都被放到了一组LRU里面。（实际上，每个zone就有一组这样的LRU，页面都被放到自己对应的zone的LRU中。）

一组LRU由几对链表组成，有磁盘高速缓存页面的链表（包括文件映射页面）、匿名映射页面的链表等等。

一对链表实际上是active和inactive两个链表，前者是最近使用过的页面，后者是最近未使用的页面。

**进行页面回收时，PFRA要做两件事，一是将active链表中的最近最少使用的页面移动到inactive链表，二是尝试将inactive链表中最近最少使用的页面回收。**

### 确定最近最少使用

现在面临的问题就是：**怎么确定active/inactive链表中哪些页面是最近最少使用的呢？**

一种方法是排序，当页面被访问时，将其移动到链表的尾部（假设回收从头开始），但这意味着页面在链表中的位置可能频繁移动，并且移动之前还必须先上锁（可能有多个CPU在同时访问），这样对效率影响很大。

**Linux内核采用的是标记加顺序的方法。当页面在active和inactive两个链表之间移动时，总是将其放到链表的尾部**。

页面没有在链表间移动时，并不会调整它们的顺序。而是通过访问标记来表示页面是否刚被访问过。如果inactive链表中已设置访问标记的页面再次被访问，则将其移动到active链表中，并且清除访问标记。

页面的访问标记有两种情况，一是放在page->flags中的PG\_referenced标记，在页面被访问时该标记置位。对于磁盘高速缓存中的页面，用户进程通过read、write之类的系统调用去访问它们，系统调用代码中会将对应页面的PG\_referenced置位。

而对于内存映射的页面，用户进程可以直接访问它们（不经过内核），所以这种情况下的访问标记不是由内核来设置的，而是MMU。在将虚拟地址映射成物理地址后，MMU会在对应的页表项上设置一个accessed标志位，表示页面被访问。（同样的道理，MMU会在被写的页面所对应的页表项上置一个dirty标志，表示页面是脏页面。）

页面的访问标记将在PFRA处理页面回收的过程中被清除，因为访问标记显然是应该有有效期的，而PFRA的运行周期就代表这个有效期。page->flags中的PG\_referenced标记可以直接清除，而页表项中的accessed位则需要通过页面找到其对应的页表项后才能清除（“反向映射”）。

那么，回收过程又是如何扫描LRU链表的呢？

由于存在多组LRU（系统中有多个zone，每个zone又有多组LRU），如果PFRA每次回收都扫描所有的LRU找出其中最值得回收的若干个页面的话，回收算法的效率显然不够理想。

Linux内核PFRA使用的扫描方法是：定义一个扫描优先级，通过这个优先级换算出在每个LRU上应该扫描的页面数。整个回收算法以最低的优先级开始，先扫描LRU中最近最少使用的几个页面，然后试图回收它们。如果扫描一遍之后，已经回收了足够数量的页面，则本次回收结束，否则，增大优先级，重新扫描，直到足够数量的页面被回收。

每次扫描一个LRU时，都从active链表和inactive链表获取当前优先级对应数目的页面。

PFRA不倾向于从active链表回收匿名映射的页面，因为用户进程使用的内存一般相对较少，且回收的话需要进行交换，代价较大。所以在剩余内存较多、匿名映射所占比例较少的情况下，都不会去回收匿名映射对应的active链表中的页面。

### 反向映射

如果页面没有被映射，直接回收到伙伴系统即可（对于脏页，先写回、再回收）。否则，因为用户进程的某个页表项正引用着这个页面，在回收页面之前，必须给引用它的页表项一个交代。为此，啮合建立了从页面到页表项的反向映射。

通过反向映射可以找到一个被映射页面对应的vma，通过vma->vm_mm->pgd就能找到对应的页表。然后通过page->index得到页面的虚拟地址。再通过虚拟地址从页表中找到对应的页表项。


### 页面的换入换出

在找到了引用待回收页面的页表项之后，对于文件映射，可以直接把引用该页面的页表项清空。等用户再访问这个地址时触发缺页异常，异常处理代码再重新分配一个页面，并去磁盘里面把对应的数据读出来就行了，这就跟页面映射以后，第一次被访问的情形一样；

对于匿名映射，先将页面写回到交换文件，然后还得在页表项中记录该页面在交换文件中的index。



### 最后的必杀

前面提到，PFRA可能扫描了所有的LRU还没办法回收需要的页面。同样，在slab、dentry cache、inode cache等地方，可能也无法回收到页面。

这时，如果某段内核代码一定要获得页面呢？PFRA最后的必杀技————OOM（out of memory）。所谓的OOM就是寻找一个最不重要的进程，然后将其杀死。通过释放这个进程所占有的内存页面，以缓解系统压力。

## 内存管理架构

![](https://i.imgur.com/CqYZypR.png)

### 物理内存管理

物理内存是如何分配的呢？

首先，Linux支持NUMA(非统一内存访问架构)，物理内存管理的第一个层次就是介质的管理。pg\_data\_t结构就描述了介质。一般而言，我们的内存管理介质只有内存，并且它是均匀的，所以可以简单地认为系统中只有一个pg\_data\_t对象。

每一种介质下面有若干个zone，一般是DMA、NORMAL、HIGHMEM。

- **DMA**:因为有些硬件系统的DMA总线比系统总线窄，所以只有一部分地址空间能够用作DMA，这部分地址被管理在DMA区域（属于高级货）。
- **HIGHMEM**：高端内存。在32位系统中，地址空间是4G，其中规定3G~4G是内核空间，0~3G是用户空间（每个用户进程都有这么大的虚拟空间）。内核的地址映射是写死的，它映射到物理地址的0~1G上。实际上大于896MB的物理地址是没有写死的页表来对应的，内核不能直接访问它们（必须要建立映射），故称他们为高端内存（如果机器内存小于896MB，就没有高端内存；如果是64位机器，也不存在高端内存，因为地址空间很大，属于内核的空间也不止1G了）。
- **NORMAL**：不属于DMA或HIGHMEM的内存就叫NORMAL。

在zone之上的zone_list代表了分配策略，即内存分配时的zone优先级。**一种内存分配往往不是只能在一个zone里进行分配的，比如分配一个页给内核使用，最优先是从NORMAL里分配，不行的话就分配DMA里面的（HIGH就不行，因为还没建立映射），这就是一种分配策略。

每一内存介质维护了一个mem\_map,为介质中的每一个物理页面建立了一个page结构与之对应，以便管理物理内存。

每个zone记录着它在mem\_map上的起始位置。并通过free\_area串联这个zone上空闲的page。物理内存的分配就是从这里来的，从free\_area上把page摘下，就算是分配了。（内核的内存分配与用户进程不同，用户使用内存会被内核监督，使用不当就会产生“段错误”；而内核则无人监督，只能靠自觉，不是自己从free\_area摘下的page就不要乱用。）
![](https://i.imgur.com/NwhIS53.png)

### 建立地址映射
内核需要物理内存时，很多情况是整页分配的，在mem\_map中摘一个page下来就好。
那么内核在分配page、建立地址映射的过程中，使用的是虚拟地址还是物理地址呢？

首先，内核代码所访问的地址都是虚拟地址，因为CPU指令接受的就是虚拟地址（地址映射对于CPU指令是透明的）。但是，建立地址映射时，内核在页表里面填写的内容却是物理地址，因为地址映射的目标就是要得到物理地址。

那么，内核怎么得到这个物理地址呢？

上面提到，mem\_map中的page就是根据物理内存来建立的，每一个page就对应了一个物理页。
于是我们可以认为，虚拟地址的映射是靠这里page结构来完成的，是它们给出了最终的物理地址。然而，page结构显然是通过虚拟地址来管理的（CPU指令接受的就是虚拟地址）。那么，page结构实现了别人的虚拟地址映射，谁又来实现page结构自身的虚拟地址映射呢？

这就引出了前面提到的，内核空间的页表项是写死的。内核初始化时，内核的地址空间就已经把地址映射写死了。page结构显然存在于内核空间，所以它的地址映射问题已经通过“写死”解决了。